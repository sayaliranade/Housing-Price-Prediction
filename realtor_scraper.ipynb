{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb717d5-f0a3-4394-b50b-0db6c3e11701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f2c6ab-1fbd-4b05-b776-6bed01531b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_city(city, state = \"CA\"):\n",
    "    \"\"\"\n",
    "    This function searches for information about recently sold houses in the chosen city on realtor.com\n",
    "    Individual pages for each house are saved locally as html files in the folder named after the city of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating folder for the city data if it does not already exist\n",
    "    if not os.path.exists(city):\n",
    "        os.makedirs(city)\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36', \n",
    "               'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    session = requests.Session()\n",
    "    \n",
    "    url = \"https://www.realtor.com/realestateandhomes-search/{}_{}/show-recently-sold\".format(city, state)\n",
    "    search_page = session.get(url, headers = headers)\n",
    "    search_page = BeautifulSoup(search_page.content, 'html.parser')\n",
    "    sleep(random.randint(5, 10))\n",
    "    \n",
    "    # extracting the number of pages\n",
    "    count_results = search_page.find_all('span', {\"data-testid\": \"results-header-count\"})[0].text\n",
    "    count_results = count_results.split(\" \")[0]\n",
    "    count_results = int(count_results.replace(\",\", \"\"))\n",
    "    num_pages = int(count_results / 42) + 1\n",
    "    \n",
    "    k = 0\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        # assessing search pages one by one\n",
    "        url_page = url + \"/pg-{}\".format(str(page_num))\n",
    "        search_page = session.get(url_page, headers = headers)\n",
    "        sleep(random.randint(5, 10))\n",
    "        search_page = BeautifulSoup(search_page.content, 'html.parser')\n",
    "        homes = search_page.find_all('a', {\"data-testid\": \"property-anchor\"})\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(homes):\n",
    "            # extracting links to individual house pages from the search page\n",
    "            home_url = homes[i]['href']\n",
    "            # requesting individual house pages and saving locally them as html files\n",
    "            home_page = session.get(\"https://www.realtor.com/\" + home_url, headers = headers)\n",
    "            with open(\"{}/home_page_{}.html\".format(city, str(k)), 'wb') as f:\n",
    "                f.write(home_page.content)\n",
    "            sleep(random.randint(5, 10))\n",
    "            i += 1\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029cfc66-b402-4a7c-b693-61d8a8d923de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_home_pages(folder, output_file_name):\n",
    "    \"\"\"\n",
    "    This function scrapes the data from individual house pages downloaded from realtor.com\n",
    "    The data is then aggregated as a table and is saved as a csv file\n",
    "    \n",
    "    Parameters:\n",
    "    folder (str): path to the folder with downloaded house pages\n",
    "    output_file_name(str): path to save the resulting csv file\n",
    "    \n",
    "    Return:\n",
    "    pd.DataFrame containing aggregated housing information\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {\"sold_date\": [],\n",
    "            \"bedrooms\": [],\n",
    "            \"bathrooms\": [],\n",
    "            \"build_year\": [],\n",
    "            \"build_type\": [],\n",
    "            \"area\": [],\n",
    "            \"lot_area\": [],\n",
    "            \"parking_spots\": [],\n",
    "            \"homeowners_association\": [],\n",
    "            \"zip_code\": [], \n",
    "            \"nearby_elem_school\": [],\n",
    "            \"nearby_middle_school\": [],\n",
    "            \"nearby_high_school\": [],\n",
    "            \"nh_median_price\": [],\n",
    "            \"nh_days_on_market\": [],\n",
    "            \"nh_price_per_sqft\": [],\n",
    "            \"selling_broker\": [],\n",
    "            \"buying_broker\": [],\n",
    "            \"price\": []}\n",
    "    \n",
    "    for filename in tqdm(os.listdir(folder)):\n",
    "        try:\n",
    "            file = open(\"{}/{}\".format(folder, filename), \"r\", encoding = 'utf8')\n",
    "            home = BeautifulSoup(file.read(), 'html.parser')\n",
    "\n",
    "            # extracting sold date\n",
    "            sold_date = home.find_all('span', {\"data-label\": \"property-meta-sold-date\"})[0].text[8:]\n",
    "            sold_date = sold_date[: len(sold_date) - 1]\n",
    "            sold_date = datetime.strptime(sold_date, '%B %d, %Y')\n",
    "\n",
    "            # bedrooms\n",
    "            beds = home.find_all('li', {\"data-label\": \"property-meta-beds\"})[0]\n",
    "            beds = beds.find_all('span', {\"class\": \"data-value\"})[0].text\n",
    "            beds = int(beds)\n",
    "\n",
    "            # bathrooms\n",
    "            baths = home.find_all('li', {\"data-label\": \"property-meta-bath\"})[0]\n",
    "            baths = baths.find_all('span', {\"class\": \"data-value\"})[0].text\n",
    "            baths = int(baths)\n",
    "\n",
    "            def search_public_records(public_records, keyterm, to_drop = []):\n",
    "                output = public_records[public_records.index(keyterm) + len(keyterm): ]\n",
    "                end_pos = output.find(\"\\n\")\n",
    "                if end_pos > -1:\n",
    "                    output = output[: end_pos]\n",
    "                for elem in to_drop:\n",
    "                    output = output.replace(elem, \"\")\n",
    "                return output\n",
    "\n",
    "            public_records = home.find_all('div', {\"id\": \"ldp-detail-public-records\"})[0].text\n",
    "\n",
    "            # year built\n",
    "            build_year = search_public_records(public_records, \"Year built: \")\n",
    "            build_year = int(build_year)\n",
    "\n",
    "            # building type\n",
    "            build_type = search_public_records(public_records, \"Property type: \")\n",
    "\n",
    "            # area\n",
    "            area = search_public_records(public_records, \"House size: \", to_drop = [\",\", \" sq ft\"])\n",
    "            area = int(area)\n",
    "\n",
    "            # lot_area\n",
    "            lot_area = search_public_records(public_records, \"Lot size: \")\n",
    "            lot_area = int(lot_area)\n",
    "\n",
    "            # parking\n",
    "            try:\n",
    "                parking = home.text[home.text.index(\"Parking Total: \") + len(\"Parking Total: \"): ]\n",
    "                parking = int(parking.split(\" \")[0])\n",
    "            except:\n",
    "                parking = 0\n",
    "\n",
    "            # homeowners association\n",
    "            try:\n",
    "                ha = home.text[home.text.index(\"Association: \") + len(\"Association: \"): ]\n",
    "                ha = str(ha.split(\" \")[0])\n",
    "                if ha.startswith(\"No\"):\n",
    "                    ha = False\n",
    "                else:\n",
    "                    ha = True\n",
    "            except:\n",
    "                ha = False\n",
    "\n",
    "            # zip code\n",
    "            zip_code = home.find_all('span', {\"itemprop\": \"postalCode\"})[0].text\n",
    "\n",
    "            # distance to the nearest schools\n",
    "            schools = home.find_all('table', {\"class\": \"table table-clear table-heading-unstyled table-school school-rating-lg\"})[0].text.split(\"\\n\")\n",
    "            schools = [s for s in schools if \" mi\" in s]\n",
    "            schools = schools[0:3]\n",
    "            schools = [float(s.split(\" \")[0]) for s in schools]\n",
    "            nearby_elem_school, nearby_middle_school, nearby_high_school = schools\n",
    "\n",
    "            # neighborhood\n",
    "            nh = home.find_all('div', {\"class\": \"neighborhood-flex-item\"})\n",
    "\n",
    "            # median sales price in the neighborhood\n",
    "            nh_median_price = nh[1].text\n",
    "            nh_median_price = nh_median_price[nh_median_price.index(\"$\") + 1: nh_median_price.index(\"Median Sales Price\")]\n",
    "            nh_median_price = int(nh_median_price.replace(\",\", \"\"))\n",
    "\n",
    "            # median days on the market for the neighborhood\n",
    "            nh_days_on_market = nh[2].text\n",
    "            nh_days_on_market = nh_days_on_market[: nh_days_on_market.index(\"Median Days on Market\")]\n",
    "            nh_days_on_market = int(nh_days_on_market)\n",
    "\n",
    "            # median price per sq ft in the neighborhood\n",
    "            nh_price_per_sqft = nh[3].text\n",
    "            nh_price_per_sqft = nh_price_per_sqft[nh_price_per_sqft.index(\"$\") + 1: nh_price_per_sqft.index(\"Price Per Sq Ft\")]\n",
    "            nh_price_per_sqft = int(nh_price_per_sqft.replace(\",\", \"\"))\n",
    "\n",
    "            # selling broker\n",
    "            selling_broker = home.find_all('span', {\"data-label\": \"branding-seller-broker-name\"})[0].text[1:]\n",
    "\n",
    "            # buying broker\n",
    "            buying_broker = home.find_all('span', {\"data-label\": \"branding-buyer-broker-name\"})[0].text[1:]\n",
    "\n",
    "            # price\n",
    "            price = home.find_all('div', {\"class\": \"display-inline\"})[1].text\n",
    "            price = price[price.index(\"$\") + 1: ]\n",
    "            price = price[: price.index(\" \")]\n",
    "            price = price.replace(\",\", \"\")\n",
    "            price = int(price)\n",
    "\n",
    "            # aggregating the data for individual homes\n",
    "            data[\"sold_date\"].append(sold_date)\n",
    "            data[\"bedrooms\"].append(beds)\n",
    "            data[\"bathrooms\"].append(baths)\n",
    "            data[\"build_year\"].append(build_year)\n",
    "            data[\"build_type\"].append(build_type)\n",
    "            data[\"area\"].append(area)\n",
    "            data[\"lot_area\"].append(lot_area)\n",
    "            data[\"parking_spots\"].append(parking)\n",
    "            data[\"homeowners_association\"].append(ha)\n",
    "            data[\"zip_code\"].append(zip_code)\n",
    "            data[\"nearby_elem_school\"].append(nearby_elem_school)\n",
    "            data[\"nearby_middle_school\"].append(nearby_middle_school)\n",
    "            data[\"nearby_high_school\"].append(nearby_high_school)\n",
    "            data[\"nh_median_price\"].append(nh_median_price)\n",
    "            data[\"nh_days_on_market\"].append(nh_days_on_market)\n",
    "            data[\"nh_price_per_sqft\"].append(nh_price_per_sqft)\n",
    "            data[\"selling_broker\"].append(selling_broker)\n",
    "            data[\"buying_broker\"].append(buying_broker)\n",
    "            data[\"price\"].append(price)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file_name, index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ad917-0540-4ac9-89c8-66cf95faafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_city(\"San-Francisco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9fb1df-f05f-435a-a46a-9e1be0c55493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b16c634610487f9ad7e15357f9bb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = scrape_home_pages(\"San-Francisco\", \"sf_sold_houses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292f547a-1df3-4e38-aa3c-5f125e2588d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1899 entries, 0 to 1898\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   sold_date               1899 non-null   object \n",
      " 1   bedrooms                1899 non-null   int64  \n",
      " 2   bathrooms               1899 non-null   int64  \n",
      " 3   build_year              1899 non-null   int64  \n",
      " 4   build_type              1899 non-null   object \n",
      " 5   area                    1899 non-null   int64  \n",
      " 6   lot_area                1899 non-null   int64  \n",
      " 7   parking_spots           1899 non-null   int64  \n",
      " 8   homeowners_association  1899 non-null   bool   \n",
      " 9   zip_code                1899 non-null   int64  \n",
      " 10  nearby_elem_school      1899 non-null   float64\n",
      " 11  nearby_middle_school    1899 non-null   float64\n",
      " 12  nearby_high_school      1899 non-null   float64\n",
      " 13  nh_median_price         1899 non-null   int64  \n",
      " 14  nh_days_on_market       1899 non-null   int64  \n",
      " 15  nh_price_per_sqft       1899 non-null   int64  \n",
      " 16  selling_broker          1899 non-null   object \n",
      " 17  buying_broker           1899 non-null   object \n",
      " 18  price                   1899 non-null   int64  \n",
      "dtypes: bool(1), float64(3), int64(11), object(4)\n",
      "memory usage: 269.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c69eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating mongodb collection\n",
    "\n",
    "import pymongo\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "mydb = myclient[\"realtor_data\"]\n",
    "\n",
    "mycol = mydb[\"SF_houses\"]\n",
    "\n",
    "mycol.insert_one({\"index\":\"sold_date\",\"data\":df.to_dict(\"records\")})\n",
    "\n",
    "myclient.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
